{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35581b4a-4a49-4efd-a50b-2ba112ac98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca84c24c-5826-45f5-afa2-d01e974964c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into dataframe\n",
    "Data_frame = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb6711d-f268-4eb4-a064-a67fa02b0f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Basic infomation about data\n",
    "Data_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac542a8-4ae4-4262-b319-6272b5b721d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making dataframe copy to prevent original data\n",
    "Data_frame_copy = Data_frame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486ed605-e576-45f6-b819-aaabb2edd6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using label encoder to encode columns like Geography and Gender which are object type\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "Selected_columns = [\"Geography\",\"Gender\"]\n",
    "for column in Selected_columns:\n",
    "    Data_frame_copy[column] = LE.fit_transform(Data_frame_copy[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d499c506-66b6-40da-97ae-b60d880866f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping columns which are not required for model building\n",
    "Data_frame_copy.drop(columns=['RowNumber','CustomerId','Surname'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "120ea19b-5854-4641-8213-042b58b04546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data into Independent and Dependent variables\n",
    "y = Data_frame_copy.Exited.values\n",
    "x = Data_frame_copy.drop(columns=['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0eaf558-4802-449c-b054-6b93cbb949f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=20,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851ba4b9-42d6-4720-9011-1cd5e03a7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_x = StandardScaler()\n",
    "x_train = std_x.fit_transform(x_train)\n",
    "x_test = std_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36ab4eac-47c8-4499-b1d3-425b6be77466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries required for building neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Conv1D,Flatten\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad18a6a8-c235-4dc9-b8cd-120e271eacc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omkar Chemate\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Defining neural network structure\n",
    "# First input layer which as 10 nodes for input of 10 variables\n",
    "# Second hidden layer having 100 nodes and relu as activation function (read about different activation funcitons like sigmoid, tanh, and more\n",
    "# Output layer having one node which return value between 0 to 1\n",
    "model=Sequential()\n",
    "model.add(Flatten(input_shape=(10,))) #In this case, input_shape=(10,) means that the input to this layer will have 10 features (or elements).\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid')) # Since there's only one output neuron with a sigmoid activation, the model is set up to predict a probability (0 to 1) for a binary outcome (like \"will the customer leave or not?\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e5a20ce-e285-4480-ab5f-42dc540043a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model using adam optimizer (read about different optimizer)\n",
    "model.compile(optimizer='adam',metrics=['accuracy'],loss='BinaryCrossentropy') #compile -  it sets up how the model will learn from the data.\n",
    "# Adam (short for Adaptive Moment Estimation) is - helps in speeding up the training process and achieving better performance.\n",
    "# Metrics are used to evaluate the performance of the model during training and testing. In this case, you're using accuracy as the metric.\n",
    "# Accuracy measures how often the model correctly predicts the class labels\n",
    "# The loss function quantifies how well the model's predictions match the actual labels. The goal during training is to minimize this loss.\n",
    "# Binary Crossentropy is a loss function used for binary classification tasks. It measures the dissimilarity between the predicted probabilities and the actual labels (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9075c764-c022-48d1-81c6-6300503a7fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7367 - loss: 0.5300 - val_accuracy: 0.8253 - val_loss: 0.4002\n",
      "Epoch 2/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8230 - loss: 0.4091 - val_accuracy: 0.8600 - val_loss: 0.3542\n",
      "Epoch 3/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8457 - loss: 0.3706 - val_accuracy: 0.8733 - val_loss: 0.3343\n",
      "Epoch 4/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8542 - loss: 0.3551 - val_accuracy: 0.8707 - val_loss: 0.3290\n",
      "Epoch 5/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8524 - loss: 0.3470 - val_accuracy: 0.8693 - val_loss: 0.3280\n",
      "Epoch 6/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8571 - loss: 0.3340 - val_accuracy: 0.8667 - val_loss: 0.3271\n",
      "Epoch 7/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8580 - loss: 0.3356 - val_accuracy: 0.8773 - val_loss: 0.3258\n",
      "Epoch 8/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8551 - loss: 0.3436 - val_accuracy: 0.8627 - val_loss: 0.3311\n",
      "Epoch 9/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8563 - loss: 0.3385 - val_accuracy: 0.8787 - val_loss: 0.3251\n",
      "Epoch 10/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8643 - loss: 0.3355 - val_accuracy: 0.8773 - val_loss: 0.3257\n",
      "Epoch 11/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8595 - loss: 0.3270 - val_accuracy: 0.8733 - val_loss: 0.3185\n",
      "Epoch 12/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8685 - loss: 0.3306 - val_accuracy: 0.8680 - val_loss: 0.3169\n",
      "Epoch 13/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8698 - loss: 0.3207 - val_accuracy: 0.8707 - val_loss: 0.3310\n",
      "Epoch 14/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8640 - loss: 0.3223 - val_accuracy: 0.8733 - val_loss: 0.3200\n",
      "Epoch 15/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8737 - loss: 0.3083 - val_accuracy: 0.8733 - val_loss: 0.3123\n",
      "Epoch 16/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8667 - loss: 0.3132 - val_accuracy: 0.8800 - val_loss: 0.3155\n",
      "Epoch 17/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8716 - loss: 0.3062 - val_accuracy: 0.8693 - val_loss: 0.3157\n",
      "Epoch 18/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8667 - loss: 0.3147 - val_accuracy: 0.8653 - val_loss: 0.3223\n",
      "Epoch 19/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8737 - loss: 0.3038 - val_accuracy: 0.8720 - val_loss: 0.3219\n",
      "Epoch 20/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8783 - loss: 0.2927 - val_accuracy: 0.8747 - val_loss: 0.3166\n",
      "Epoch 21/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8759 - loss: 0.2991 - val_accuracy: 0.8760 - val_loss: 0.3196\n",
      "Epoch 22/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.2908 - val_accuracy: 0.8733 - val_loss: 0.3241\n",
      "Epoch 23/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8723 - loss: 0.3025 - val_accuracy: 0.8707 - val_loss: 0.3328\n",
      "Epoch 24/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8761 - loss: 0.2939 - val_accuracy: 0.8693 - val_loss: 0.3253\n",
      "Epoch 25/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8729 - loss: 0.3029 - val_accuracy: 0.8747 - val_loss: 0.3228\n",
      "Epoch 26/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8659 - loss: 0.3022 - val_accuracy: 0.8640 - val_loss: 0.3328\n",
      "Epoch 27/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8784 - loss: 0.2952 - val_accuracy: 0.8760 - val_loss: 0.3204\n",
      "Epoch 28/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8810 - loss: 0.2852 - val_accuracy: 0.8653 - val_loss: 0.3296\n",
      "Epoch 29/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8786 - loss: 0.2897 - val_accuracy: 0.8653 - val_loss: 0.3311\n",
      "Epoch 30/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.2865 - val_accuracy: 0.8640 - val_loss: 0.3275\n",
      "Epoch 31/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8730 - loss: 0.2993 - val_accuracy: 0.8733 - val_loss: 0.3240\n",
      "Epoch 32/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.2808 - val_accuracy: 0.8707 - val_loss: 0.3285\n",
      "Epoch 33/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8747 - loss: 0.2922 - val_accuracy: 0.8720 - val_loss: 0.3249\n",
      "Epoch 34/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8833 - loss: 0.2751 - val_accuracy: 0.8707 - val_loss: 0.3335\n",
      "Epoch 35/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8841 - loss: 0.2818 - val_accuracy: 0.8693 - val_loss: 0.3291\n",
      "Epoch 36/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8855 - loss: 0.2821 - val_accuracy: 0.8640 - val_loss: 0.3314\n",
      "Epoch 37/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8809 - loss: 0.2835 - val_accuracy: 0.8733 - val_loss: 0.3335\n",
      "Epoch 38/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8906 - loss: 0.2614 - val_accuracy: 0.8653 - val_loss: 0.3406\n",
      "Epoch 39/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8870 - loss: 0.2684 - val_accuracy: 0.8720 - val_loss: 0.3353\n",
      "Epoch 40/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8834 - loss: 0.2717 - val_accuracy: 0.8587 - val_loss: 0.3417\n",
      "Epoch 41/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8900 - loss: 0.2707 - val_accuracy: 0.8640 - val_loss: 0.3467\n",
      "Epoch 42/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8870 - loss: 0.2667 - val_accuracy: 0.8747 - val_loss: 0.3390\n",
      "Epoch 43/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8873 - loss: 0.2660 - val_accuracy: 0.8507 - val_loss: 0.3483\n",
      "Epoch 44/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.2611 - val_accuracy: 0.8600 - val_loss: 0.3482\n",
      "Epoch 45/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8947 - loss: 0.2644 - val_accuracy: 0.8653 - val_loss: 0.3476\n",
      "Epoch 46/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8874 - loss: 0.2627 - val_accuracy: 0.8573 - val_loss: 0.3458\n",
      "Epoch 47/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.2673 - val_accuracy: 0.8640 - val_loss: 0.3441\n",
      "Epoch 48/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.2566 - val_accuracy: 0.8507 - val_loss: 0.3566\n",
      "Epoch 49/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.2587 - val_accuracy: 0.8627 - val_loss: 0.3518\n",
      "Epoch 50/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8944 - loss: 0.2528 - val_accuracy: 0.8693 - val_loss: 0.3407\n",
      "Epoch 51/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8917 - loss: 0.2525 - val_accuracy: 0.8720 - val_loss: 0.3386\n",
      "Epoch 52/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8910 - loss: 0.2561 - val_accuracy: 0.8667 - val_loss: 0.3513\n",
      "Epoch 53/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8921 - loss: 0.2520 - val_accuracy: 0.8720 - val_loss: 0.3504\n",
      "Epoch 54/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8896 - loss: 0.2520 - val_accuracy: 0.8600 - val_loss: 0.3570\n",
      "Epoch 55/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8917 - loss: 0.2526 - val_accuracy: 0.8640 - val_loss: 0.3595\n",
      "Epoch 56/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8934 - loss: 0.2517 - val_accuracy: 0.8573 - val_loss: 0.3596\n",
      "Epoch 57/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9001 - loss: 0.2398 - val_accuracy: 0.8693 - val_loss: 0.3484\n",
      "Epoch 58/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.2445 - val_accuracy: 0.8560 - val_loss: 0.3546\n",
      "Epoch 59/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8983 - loss: 0.2407 - val_accuracy: 0.8480 - val_loss: 0.3782\n",
      "Epoch 60/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9019 - loss: 0.2384 - val_accuracy: 0.8707 - val_loss: 0.3524\n",
      "Epoch 61/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.2398 - val_accuracy: 0.8627 - val_loss: 0.3598\n",
      "Epoch 62/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8992 - loss: 0.2395 - val_accuracy: 0.8653 - val_loss: 0.3631\n",
      "Epoch 63/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.2303 - val_accuracy: 0.8560 - val_loss: 0.3564\n",
      "Epoch 64/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2317 - val_accuracy: 0.8627 - val_loss: 0.3585\n",
      "Epoch 65/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9005 - loss: 0.2344 - val_accuracy: 0.8627 - val_loss: 0.3636\n",
      "Epoch 66/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.2263 - val_accuracy: 0.8627 - val_loss: 0.3724\n",
      "Epoch 67/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.2261 - val_accuracy: 0.8627 - val_loss: 0.3731\n",
      "Epoch 68/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2249 - val_accuracy: 0.8653 - val_loss: 0.3801\n",
      "Epoch 69/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.2177 - val_accuracy: 0.8467 - val_loss: 0.3761\n",
      "Epoch 70/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2251 - val_accuracy: 0.8627 - val_loss: 0.3690\n",
      "Epoch 71/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9056 - loss: 0.2262 - val_accuracy: 0.8640 - val_loss: 0.3690\n",
      "Epoch 72/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2189 - val_accuracy: 0.8600 - val_loss: 0.3755\n",
      "Epoch 73/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.2271 - val_accuracy: 0.8613 - val_loss: 0.3711\n",
      "Epoch 74/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2147 - val_accuracy: 0.8560 - val_loss: 0.3777\n",
      "Epoch 75/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 0.2264 - val_accuracy: 0.8680 - val_loss: 0.3761\n",
      "Epoch 76/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2152 - val_accuracy: 0.8587 - val_loss: 0.3765\n",
      "Epoch 77/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.2179 - val_accuracy: 0.8533 - val_loss: 0.3917\n",
      "Epoch 78/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2142 - val_accuracy: 0.8547 - val_loss: 0.3846\n",
      "Epoch 79/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2057 - val_accuracy: 0.8600 - val_loss: 0.3773\n",
      "Epoch 80/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2168 - val_accuracy: 0.8480 - val_loss: 0.3941\n",
      "Epoch 81/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.2071 - val_accuracy: 0.8653 - val_loss: 0.3820\n",
      "Epoch 82/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2049 - val_accuracy: 0.8480 - val_loss: 0.3974\n",
      "Epoch 83/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2025 - val_accuracy: 0.8573 - val_loss: 0.3921\n",
      "Epoch 84/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9154 - loss: 0.2037 - val_accuracy: 0.8613 - val_loss: 0.4021\n",
      "Epoch 85/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2135 - val_accuracy: 0.8573 - val_loss: 0.4008\n",
      "Epoch 86/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2056 - val_accuracy: 0.8667 - val_loss: 0.4022\n",
      "Epoch 87/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2063 - val_accuracy: 0.8533 - val_loss: 0.4104\n",
      "Epoch 88/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.1931 - val_accuracy: 0.8560 - val_loss: 0.4021\n",
      "Epoch 89/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 0.1860 - val_accuracy: 0.8493 - val_loss: 0.4133\n",
      "Epoch 90/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9112 - loss: 0.2093 - val_accuracy: 0.8533 - val_loss: 0.4094\n",
      "Epoch 91/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.1945 - val_accuracy: 0.8560 - val_loss: 0.4238\n",
      "Epoch 92/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.1912 - val_accuracy: 0.8560 - val_loss: 0.4062\n",
      "Epoch 93/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.1915 - val_accuracy: 0.8507 - val_loss: 0.4092\n",
      "Epoch 94/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9235 - loss: 0.1856 - val_accuracy: 0.8440 - val_loss: 0.4252\n",
      "Epoch 95/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9291 - loss: 0.1861 - val_accuracy: 0.8467 - val_loss: 0.4226\n",
      "Epoch 96/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.1803 - val_accuracy: 0.8547 - val_loss: 0.4154\n",
      "Epoch 97/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9196 - loss: 0.1881 - val_accuracy: 0.8480 - val_loss: 0.4129\n",
      "Epoch 98/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.1817 - val_accuracy: 0.8560 - val_loss: 0.4235\n",
      "Epoch 99/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.1832 - val_accuracy: 0.8640 - val_loss: 0.4370\n",
      "Epoch 100/100\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.1823 - val_accuracy: 0.8480 - val_loss: 0.4191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23125e434a0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=64,validation_split=0.1,epochs=100)\n",
    "# fit(): Starts the training process for the model using the provided training data and labels.\n",
    "#x_train: Input features for training.\n",
    "#y_train: Actual labels the model will learn to predict.\n",
    "#batch_size (64): Number of samples processed before updating weights; helps manage memory and speed up training.\n",
    "#validation_split (0.1): Portion of training data (10%) used for validating the model's performance during training.\n",
    "#epochs (100): Number of times the model will train on the entire dataset; allows for more learning but risks overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e431ca08-1eb6-4305-aa3e-1af76357b608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "# Predicting values of test dataset\n",
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4b11b9b-ff24-4c68-8bf5-397e2e852c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for val in pred:\n",
    "    if val > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3f5ae28-9efa-4d17-8ab4-b5619a59d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "985c03f2-0020-4577-99a9-a6a32eac0cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1831  191]\n",
      " [ 213  265]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b813256-9268-428d-953d-f4cece6efbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8384"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca440ac-5570-4ea0-bc73-a911a01ddcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
